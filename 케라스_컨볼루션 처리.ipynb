{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 컨볼루션 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "https://victorzhou.com/blog/keras-cnn-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import mnist\n",
    "\n",
    "\n",
    "# The first time you run this might be a bit slow, since the\n",
    "# mnist package has to download and cache the data.\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "print(train_images.shape) # (60000, 28, 28)\n",
    "print(train_labels.shape) # (60000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IdxDecodeError',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'array',\n",
       " 'datasets_url',\n",
       " 'download_and_parse_mnist_file',\n",
       " 'download_file',\n",
       " 'functools',\n",
       " 'gzip',\n",
       " 'numpy',\n",
       " 'operator',\n",
       " 'os',\n",
       " 'parse_idx',\n",
       " 'struct',\n",
       " 'tempfile',\n",
       " 'temporary_dir',\n",
       " 'test_images',\n",
       " 'test_labels',\n",
       " 'train_images',\n",
       " 'train_labels',\n",
       " 'urljoin',\n",
       " 'urlretrieve']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "print(train_images.shape) # (60000, 784)\n",
    "print(test_images.shape)  # (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델과 레이어 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.3676 - accuracy: 0.8930 - val_loss: 0.2101 - val_accuracy: 0.9392\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1899 - accuracy: 0.9444 - val_loss: 0.1521 - val_accuracy: 0.9568\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1453 - accuracy: 0.9576 - val_loss: 0.1289 - val_accuracy: 0.9631\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1197 - accuracy: 0.9658 - val_loss: 0.1102 - val_accuracy: 0.9688\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1054 - accuracy: 0.9689 - val_loss: 0.1046 - val_accuracy: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ca8041c308>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  train_labels, # training targets\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    "  validation_split= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10238509910665453, 0.9686999917030334]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "  test_images,\n",
    "  test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 다시 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 처리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# Build the model.\n",
    "model_ = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Load the model's saved weights.\n",
    "model_.load_weights('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the first 5 test images.\n",
    "predictions = model_.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 확장\n",
    "\n",
    "성능을 향상 시키기 위한 조정 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컨볼루션 계층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  Conv2D(num_filters, filter_size),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 10s 208us/step - loss: 0.3112 - accuracy: 0.9074 - val_loss: 0.1434 - val_accuracy: 0.9582\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 10s 208us/step - loss: 0.1259 - accuracy: 0.9629 - val_loss: 0.1018 - val_accuracy: 0.9712\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 10s 209us/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 0.0945 - val_accuracy: 0.9717\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 10s 210us/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.0842 - val_accuracy: 0.9753\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 10s 208us/step - loss: 0.0646 - accuracy: 0.9804 - val_loss: 0.0826 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ca8065aa88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  train_labels, # training targets\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    "  validation_split= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 드롭 아웃 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Dropout(0.5),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.5058 - accuracy: 0.8447 - val_loss: 0.2651 - val_accuracy: 0.9243\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.3150 - accuracy: 0.9056 - val_loss: 0.1994 - val_accuracy: 0.9456\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 111us/step - loss: 0.2707 - accuracy: 0.9184 - val_loss: 0.1698 - val_accuracy: 0.9546\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.2442 - accuracy: 0.9265 - val_loss: 0.1535 - val_accuracy: 0.9579\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.2332 - accuracy: 0.9274 - val_loss: 0.1445 - val_accuracy: 0.9592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ca808fad48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  train_labels, # training targets\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    "  validation_split= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완전 연결 계층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.3067 - accuracy: 0.9099 - val_loss: 0.1438 - val_accuracy: 0.9577\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 111us/step - loss: 0.1227 - accuracy: 0.9636 - val_loss: 0.1064 - val_accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.0840 - accuracy: 0.9743 - val_loss: 0.0880 - val_accuracy: 0.9736\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.0624 - accuracy: 0.9803 - val_loss: 0.0804 - val_accuracy: 0.9762\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.0487 - accuracy: 0.9849 - val_loss: 0.0761 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ca80a481c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  train_labels, # training targets\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    "  validation_split= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 컨볼류션 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 8\n",
    "filter_size = 3\n",
    "\n",
    "model = Sequential([\n",
    "  # See https://keras.io/layers/convolutional/#conv2d for more info.\n",
    "  Conv2D(\n",
    "    num_filters,\n",
    "    filter_size,\n",
    "    input_shape=(28, 28, 1),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation='relu',\n",
    "  ),\n",
    "  MaxPooling2D(pool_size=pool_size),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.5267 - accuracy: 0.8540 - val_loss: 0.2224 - val_accuracy: 0.9365\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.2033 - accuracy: 0.9405 - val_loss: 0.1675 - val_accuracy: 0.9503\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.1598 - accuracy: 0.9523 - val_loss: 0.1492 - val_accuracy: 0.9567\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 3s 65us/step - loss: 0.1376 - accuracy: 0.9583 - val_loss: 0.1363 - val_accuracy: 0.9592\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 3s 65us/step - loss: 0.1229 - accuracy: 0.9630 - val_loss: 0.1200 - val_accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ca80bd55c8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_images, # training data\n",
    "  train_labels, # training targets\n",
    "  epochs=5,\n",
    "  batch_size=32,\n",
    "  validation_split= 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
