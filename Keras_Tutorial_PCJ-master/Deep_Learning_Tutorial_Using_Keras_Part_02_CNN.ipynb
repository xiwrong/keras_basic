{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Tutorial Using Keras Part 02 - CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64auTbN6wEa2",
        "colab_type": "text"
      },
      "source": [
        "**제목**: Deep Learning Tutorial Using Keras Part02 - CNN (Keras로 배우는 딥러닝 튜토리얼 Part02 CNN편)<br>\n",
        "**제작자**: Park Chanjun (박찬준)<br>\n",
        "**소속**: Korea University Natural Language Processing & Artificial Intelligence Lab (고려대학교 자연언어처리&인공지능 연구실)<br>\n",
        "**Email**: bcj1210@naver.com<br>\n",
        "**참고자료**: 케라스 창시자에게 배우는 딥러닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajj76oRnwR69",
        "colab_type": "text"
      },
      "source": [
        "**컴퓨터 비전을 위한 딥러닝 (Convolution Neural Network)**\n",
        "<br>\n",
        "**CNN**\n",
        "먼저 컨브넷(Convnet)으로 불리는 합성곱 신경망(CNN)에 대해서 배운다<br>\n",
        "Convnet은 (image_height,image_width,image_channels) 크기의 입력 텐서를 사용한다.<br>\n",
        "예를 들어 MNIST 같은 경우 (28,28,1)<br>\n",
        "\n",
        "![대체 텍스트](https://taewanmerepo.github.io/2018/01/cnn/head.png)\n",
        "\n",
        "<br>\n",
        "**CNN 특징**\n",
        "Dense층은 입력 특성 공간에 있는 전역 패턴을 학습<br>\n",
        "합성곱층은 지역 패턴을 학습한다.<br>\n",
        "\n",
        "1. 학습된 패턴은 평행 이동 불변성을 지닌다. 컨브넷이 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면 다른 곳에서도 이 패턴을 인식할 수 있다.\n",
        "\n",
        "2. 컨브넷은 패턴의 공간적 계층 구조를 학습할 수 있다. 1번째 합성곱은 에지 같은 작은 지역 패턴을 학습, 2번째 합성곱 층은 첫 번째 층의 특성으로 구성된 더 큰 패턴을 학습하는 식이다. 이러한 방식을 이용하여 컨브넷은 매우 복잡하고 추상적인 시각적 개념을 효과적으로 학습할 수 있다.<br>\n",
        "\n",
        "**Feature Map, Filter**<br>\n",
        "합성곱 연산은 특성 맵(Feature Map)이라고 부르는 3D 텐서에 적용됩니다.<br>\n",
        "이 텐서는 2개의 공간축(높이,넓이)과 깊이 축(채널 축)으로 구성.\n",
        "\n",
        "즉 합성곱 연산은 입력 특성 맵에서 작은 패치들을 추출하고 이런 모든 패치에 같은 변환을 적용하여 출력 특성 맵(Output Feature Map)을 만든다.\n",
        "\n",
        "필터 !!<br>\n",
        "필터는 입력 데이터의 어떤 특성을 인코딩하게 된다.<br><br>\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))<br><br>\n",
        "(28,28,1)크기의 특성 맵을 입력받아 (26,26,32) 크기의 특성 맵을 출력한다. 즉 입력에 대해서 32개의 필터를 적용한 것 !<br>\n",
        "이 값은 응답 맵(Response Map)이라고 한다. \n",
        "<br>\n",
        "\n",
        "**합성곱의 핵심 파라미터**<br>\n",
        "1. 입력으로 부터 뽑아낼 패치의 크기: 보통 3x3, 5x5를 많이 사용\n",
        "2. 특성 뱁의 출력 깊이: 합성곱으로 계산할 필터의 수이다. \n",
        "<br>\n",
        "**사용법**\n",
        "Conv2D(output_depth,(window_height,window_width))\n",
        "<br>\n",
        "**패딩(Padding)**: 입력과 동일한 높이와 넓이를 가진 출력 특성 맵을 얻고 싶다면 패딩을 해야한다. 정보 손실 방지\n",
        "<br>\n",
        "**스트라이드**: 출력 크기에 영향을 미치는 요소이다. 얼마나 움질일지. 스트라이드가 2 라는 것은 2의 배수로 다운 샘플링 되었다는 뜻.\n",
        "<br>\n",
        "**Max Pooling**: 스트라이드 합성곱과 마찬가지로 강제적으로 특성 맵을 다운샘플링을 하는 것이 Max Pooling의 역할. 입력 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채널별 최대값을 출력한다.\n",
        "\n",
        "**왜 하는가**: 처리할 특성맵의 가중치 개수를 줄이기 위해서.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fBkPj2Av4YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MNIST 이미지에 컨브넷 훈련해보기\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "#데이터 로딩\n",
        "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
        "\n",
        "#데이터 전처리\n",
        "train_images=train_images.reshape((60000,28,28,1))\n",
        "train_images=train_images.astype('float32') /255\n",
        "\n",
        "test_images=test_images.reshape((10000,28,28,1))\n",
        "test_images=test_images.astype('float32') /255\n",
        "\n",
        "#One-hot Encoding\n",
        "train_labels=to_categorical(train_labels)\n",
        "test_labels=to_categorical(test_labels)\n",
        "\n",
        "#모델 구조\n",
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dense(10,activation='softmax')) #MNIST이니 10\n",
        "\n",
        "#모델 정보 출력\n",
        "model.summary() \n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#모델 훈련\n",
        "model.fit(train_images,train_labels,epochs=5,batch_size=64)\n",
        "\n",
        "#모델 평가\n",
        "test_loss,test_acc=model.evaluate(test_images,test_labels)\n",
        "print(\"Test_acc: \",test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QAwNEDBacMp",
        "colab_type": "text"
      },
      "source": [
        "**소규모 데이터셋에서 컨브넷 사용하기**<br>\n",
        "원본 데이터셋을 https://www.kaggle.com/c/dogs-vs-cats/data에서 내려받을 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVFObrAlacVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"code from https://github.com/gilbutITbook/006975/blob/master/5.2-using-convnets-with-small-datasets.ipynb\"\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "# 원본 데이터셋을 압축 해제한 디렉터리 경로\n",
        "original_dataset_dir = './datasets/cats_and_dogs/train'\n",
        "\n",
        "# 소규모 데이터셋을 저장할 디렉터리\n",
        "base_dir = './datasets/cats_and_dogs_small'\n",
        "if os.path.exists(base_dir):  # 반복적인 실행을 위해 디렉토리를 삭제합니다.\n",
        "    shutil.rmtree(base_dir)   \n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "# 훈련용 고양이 사진 디렉터리\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "# 훈련용 강아지 사진 디렉터리\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "# 검증용 고양이 사진 디렉터리\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "# 검증용 강아지 사진 디렉터리\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "# 테스트용 고양이 사진 디렉터리\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "# 테스트용 강아지 사진 디렉터리\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)\n",
        "\n",
        "# 처음 1,000개의 고양이 이미지를 train_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "# 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))\n",
        "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))\n",
        "print('검증용 고양이 이미지 전체 개수:', len(os.listdir(validation_cats_dir)))\n",
        "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_dogs_dir)))\n",
        "print('테스트용 고양이 이미지 전체 개수:', len(os.listdir(test_cats_dir)))\n",
        "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "#모델 생성 \n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#모델 요약 \n",
        "model.summary()\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "#모델 컴파일 \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuelycEqbmAW",
        "colab_type": "text"
      },
      "source": [
        "**데이터 전처리**\n",
        "\n",
        "1. 사진 파일을 읽습니다.\n",
        "2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩합니다.\n",
        "3. 그다음 부동 소수 타입의 텐서로 변환합니다.\n",
        "4. 픽셀 값(0에서 255 사이)의 스케일을 [0, 1] 사이로 조정합니다(신경망은 작은 입력 값을 선호합니다).\n",
        "\n",
        "케라스는 keras.preprocessing.image에 이미지 처리를 위한 헬퍼 도구들을 가지고 있습니다. <br>특히 ImageDataGenerator 클래스는 디스크에 있는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꾸어주는 파이썬 제너레이터를 만들어 줍니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgLu5B0ib35T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "for data_batch, labels_batch in train_generator:\n",
        "    print('배치 데이터 크기:', data_batch.shape)\n",
        "    print('배치 레이블 크기:', labels_batch.shape)\n",
        "    break\n",
        "\n",
        "#학습하기 \n",
        "history = model.fit_generator(\n",
        "      train_generator, #제너레이터 \n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,#제너레이터\n",
        "      validation_steps=50)\n",
        "\n",
        "model.save('cats_and_dogs_small_1.h5') #모델 저장하기 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5c1brz2cKvJ",
        "colab_type": "text"
      },
      "source": [
        "**Data Augmentation(데이터 증식)**\n",
        "<br>\n",
        "과대적합은 학습할 샘플이 너무 적어 새로운 데이터에 일반화할 수 있는 모델을 훈련시킬 수 없기 때문에 발생. <br> \n",
        "무한히 많은 데이터가 주어지면 데이터 분포의 모든 가능한 측면을 모델이 학습할 수 있을 것. <br> 데이터 증식은 기존의 훈련 샘플로부터 더 많은 훈련 데이터를 생성하는 방법.<br>  이 방법은 그럴듯한 이미지를 생성하도록 여러 가지 랜덤한 변환을 적용하여 샘플을 늘림.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBmn-gaAcd-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from https://github.com/gilbutITbook/006975/blob/master/5.2-using-convnets-with-small-datasets.ipynb\n",
        "\n",
        "#rotation_range는 랜덤하게 사진을 회전시킬 각도 범위입니다(0-180 사이).\n",
        "#width_shift_range와 height_shift_range는 사진을 수평과 수직으로 랜덤하게 평행 이동시킬 범위입니다(전체 넓이와 높이에 대한 비율).\n",
        "#shear_range는 랜덤하게 전단 변환을 적용할 각도 범위입니다.\n",
        "#zoom_range는 랜덤하게 사진을 확대할 범위입니다.\n",
        "#horizontal_flip은 랜덤하게 이미지를 수평으로 뒤집습니다. 수평 대칭을 가정할 수 있을 때 사용합니다(예를 들어, 풍경/인물 사진).\n",
        "#fill_mode는 회전이나 가로/세로 이동으로 인해 새롭게 생성해야 할 픽셀을 채울 전략입니다.\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# 이미지 전처리 유틸리티 모듈\n",
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = sorted([os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)])\n",
        "\n",
        "# 증식할 이미지 선택합니다\n",
        "img_path = fnames[3]\n",
        "\n",
        "# 이미지를 읽고 크기를 변경합니다\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "# (150, 150, 3) 크기의 넘파이 배열로 변환합니다\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# (1, 150, 150, 3) 크기로 변환합니다\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# flow() 메서드는 랜덤하게 변환된 이미지의 배치를 생성합니다.\n",
        "# 무한 반복되기 때문에 어느 지점에서 중지해야 합니다!\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 4 == 0:\n",
        "        break\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#모델 생성 \n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#모델 컴파일 \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "#데이터 증식 \n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#제너레이터 생성 \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 150 × 150 크기로 바꿉니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블을 만들어야 합니다\n",
        "        class_mode='binary')\n",
        "\n",
        "#제너레이터 생성 \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "#훈련\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)\n",
        "\n",
        "\n",
        "#모델 저장 \n",
        "model.save('cats_and_dogs_small_2.h5')\n",
        "\n",
        "\n",
        "#시각화 \n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF1Ch91BV3iC",
        "colab_type": "text"
      },
      "source": [
        "**사전 훈련된 컨브넷**\n",
        "<br>\n",
        "대규모 이미지 분류 문제를 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크 이다.<br>\n",
        "VGG,ResNet,Inception,Inception-ResNet,Xception 등.<br>\n",
        "\n",
        "1. 특성 추출 (Feature Extraction): 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아 내는 것.\n",
        "2. 미세 조정 (Fine Tuning): 특성 추출에서 사용했던 동결 모델의 사위 층 몇개를 동결에서 해제하고 모델에 새로 추가한 층과 함께 훈련하는 것.<br>\n",
        "a. 사전에 훈련된 기반 네트워크 위에 새로운 네트워크를 추가<br>\n",
        "b. 기반 네트워크를 동결<br>\n",
        "c. 새로 추가한 네트워크 훈련<br>\n",
        "d. 기반 네트워크에서 일부 층의 동결 해제<br>\n",
        "e. 동결을 해제한 층과 새로 추가한 층을 함께 훈련<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0R0dWiSWwtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#특성 추출 (Feature Extraction): 사전에 학습된 네트워크의 표현을 사용하여 새로운 샘플에서 흥미로운 특성을 뽑아 내는 것.\n",
        "#방법1) 새로운 데이터셋에서 합성곱 기반 층을 실행하고 출력을 넘파이 배열로 디스크에 저장., 그 다음 이 데이터를 독립된 완전 연결 분류기에 입력으로 사용 (비용이 적게 듬)\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#weights: 모델을 초기화할 가중치 체크포인트를 지정\n",
        "#include_top: 네트워크의 최상위 완전 연결 분류기를 포함할지 안할지\n",
        "#input_shape:  네트워크의 주입할 이미지의 텐서의 크기\n",
        "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))\n",
        "\n",
        "conv_base.summary()\n",
        "\n",
        "\n",
        "base_dir = './datasets/cats_and_dogs_small'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 20\n",
        "\n",
        "#Featur 추출 함수 \n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "    \n",
        "    i = 0\n",
        "    \n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = conv_base.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            # 제너레이터는 루프 안에서 무한하게 데이터를 만들어내므로 모든 이미지를 한 번씩 처리하고 나면 중지합니다\n",
        "            break\n",
        "    return features, labels\n",
        "\n",
        "#적용 \n",
        "train_features, train_labels = extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
        "test_features, test_labels = extract_features(test_dir, 1000)\n",
        "\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "#모델 정의\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#모델 학습 \n",
        "history = model.fit(train_features, train_labels,\n",
        "                    epochs=30,\n",
        "                    batch_size=20,\n",
        "                    validation_data=(validation_features, validation_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7lSsNxzdW-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#방법2) 준비한 모델 위에 Dense층을 쌓아 확장. (비용이 많이 듬)\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "#모델 정의\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(conv_base) #준비한 모델!!\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#모델 요약 \n",
        "model.summary()\n",
        "\n",
        "print('conv_base를 동결하기 전 훈련되는 가중치의 수:', \n",
        "      len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False #동결하기 \n",
        "\n",
        "\n",
        "print('conv_base를 동결한 후 훈련되는 가중치의 수:', \n",
        "      len(model.trainable_weights))\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#데이터 증식 \n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      shear_range=0.1,\n",
        "      zoom_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#제너레이터 생성 \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지의 크기를 150 × 150로 변경합니다\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # binary_crossentropy 손실을 사용하므로 이진 레이블이 필요합니다\n",
        "        class_mode='binary')\n",
        "\n",
        "#제너레이터 생성 \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "#모델 컴파일 \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "#모델 요약 \n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)\n",
        "\n",
        "\n",
        "#모델 저장 \n",
        "model.save('cats_and_dogs_small_3.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uX0wP8Zd6kJ",
        "colab_type": "text"
      },
      "source": [
        "**미세조정 실습**<br>\n",
        "\n",
        "왜 더 많은 층을 미세조정 하지 않는 것인가?<br>\n",
        "1. 합성곱 기반 층에 있는 하위 층들은 좀 더 일반적이고 재사용 가능한 특성들을 인코딩한다. 반면에 상위 층은 좀 더 특화 된 특성을 인코딩 한다. 새로운 문제에 재활용 하도록 수정이 필요한 것은 구체적인 특성들이므로 이들을 미세조정하는 것이 좋음. 하위 층으로 갈 수록 미세 조정에 대한 효과가 감소한다.\n",
        "2. 훈련해야 할 파라미터가 많을 수록 고대적합 위험이 커지기에."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8ob15Jbd77K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.summary()\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)\n",
        "\n",
        "model.save('cats_and_dogs_small_4.h5')\n",
        "\n",
        "#시각화 \n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#성능 측정 \n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}