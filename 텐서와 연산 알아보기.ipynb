{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 텐서\n",
    "텐서는 다차원 배열입니다. 넘파이(NumPy) ndarray 객체와 비슷하며, tf.Tensor 객체는 데이터 타입과 크기를 가지고 있습니다. \n",
    "또한 tf.Tensor는 GPU 같은 가속기 메모리에 상주할 수 있습니다. 텐서플로는 텐서를 생성하고 이용하는 풍부한 연산 라이브러리(tf.add, tf.matmul, tf.linalg.inv 등.)를 제공합니다. \n",
    "이러한 연산은 자동으로 텐서를 파이썬 네이티브(native) 타입으로 변환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# 연산자 오버로딩(overloading) 또한 지원합니다.\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 넘파이 배열과 tf.Tensor의 가장 확연한 차이는 다음과 같습니다:\n",
    "\n",
    "텐서는 가속기 메모리(GPU, TPU와 같은)에서 사용할 수 있습니다.\n",
    "텐서는 불변성(immutable)을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 넘파이 호환성\n",
    "\n",
    "텐서와 넘파이 배열 사이의 변환은 다소 간단합니다.\n",
    "\n",
    " - 텐서플로 연산은 자동으로 넘파이 배열을 텐서로 변환합니다.\n",
    " - 넘파이 연산은 자동으로 텐서를 넘파이 배열로 변환합니다.\n",
    " - 텐서는 .numpy() 메서드(method)를 호출하여 넘파이 배열로 변환할 수 있습니다. \n",
    " \n",
    "가능한 경우, tf.Tensor와 배열은 메모리 표현을 공유하기 때문에 이러한 변환은 일반적으로 간단(저렴)합니다. \n",
    "그러나 tf.Tensor는 GPU 메모리에 저장될 수 있고, 넘파이 배열은 항상 호스트 메모리에 저장되므로, 이러한 변환이 항상 가능한 것은 아닙니다. \n",
    "따라서 GPU에서 호스트 메모리로 복사가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환합니다.\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환합니다.\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환합니다.\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환합니다.\")\n",
    "print(np.add(tensor, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".numpy() 메서드는 텐서를 넘파이 배열로 변환합니다.\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "print(\".numpy() 메서드는 텐서를 넘파이 배열로 변환합니다.\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 가속\n",
    "\n",
    "대부분의 텐서플로 연산은 GPU를 사용하여 가속화됩니다. 어떠한 코드를 명시하지 않아도, 텐서플로는 연산을 위해 CPU 또는 GPU를 사용할 것인지를 자동으로 결정합니다. \n",
    "\n",
    "필요시 텐서를 CPU와 GPU 메모리 사이에서 복사합니다.\n",
    "연산에 의해 생성된 텐서는 전형적으로 연산이 실행된 장치의 메모리에 의해 실행됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용이 가능한가 : \n",
      "False\n",
      "텐서가 GPU #0에 있는가 : \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"GPU 사용이 가능한가 : \"),\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"텐서가 GPU #0에 있는가 : \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "10 loops: 154.69ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "  start = time.time()\n",
    "  for loop in range(10):\n",
    "    tf.matmul(x, x)\n",
    "\n",
    "  result = time.time()-start\n",
    "\n",
    "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "# CPU에서 강제 실행합니다.\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "  x = tf.random.uniform([1000, 1000])\n",
    "  assert x.device.endswith(\"CPU:0\")\n",
    "  time_matmul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU #0가 이용가능시 GPU #0에서 강제 실행합니다.\n",
    "if tf.test.is_gpu_available():\n",
    "  print(\"On GPU:\")\n",
    "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"GPU:0\")\n",
    "    time_matmul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
